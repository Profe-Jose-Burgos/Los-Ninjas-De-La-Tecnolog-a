# -*- coding: utf-8 -*-
"""Proyect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ba-uJ2R7fAY2a7N0ial2fKyRhh9_iOW3
"""

!pip install mlxtend==0.20.0

!pip install tensorflow-gpu

from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input
from keras.optimizers import Adam
from keras.callbacks import TensorBoard, ModelCheckpoint
from keras.utils import np_utils
import os
import numpy as np
from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator 
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
import cv2
import matplotlib.pyplot as plt
from keras.models import load_model
from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score
from sklearn import metrics
from mlxtend.plotting import plot_confusion_matrix
import numpy as np
import tensorflow as tf

#from modules import *
class model:
    def __init__(self,data_train,data_test,class_numbers,epochs,batch_size,width=224,height=224,channel=3):
        self.data_train=data_train
        self.data_test=data_test
        self.class_numbers=class_numbers
        self.epochs=epochs
        self.batch_size=batch_size
        self.WidthShape=width
        self.HeightShape=height
        self.channel=channel
    def set_image_datagen(self,rotation,zoom,w_shift,h_shift,preprocessing,HorizontalFlip=True,VerticalFlip=False):
        data_gen=ImageDataGenerator(
            rotation_range=rotation,
            zoom_range=zoom,
            width_shift_range=w_shift,
            height_shift_range=h_shift,
            horizontal_flip=HorizontalFlip,
            vertical_flip=VerticalFlip,
            preprocessing_function=preprocessing
        )
        return data_gen
    def set_image_generator(self,data_gen,class_mode,data_test_train_dir):
        self.class_mode=class_mode
        train_test_gen=data_gen.flow_from_directory(
            data_test_train_dir,
            target_size=(self.WidthShape,self.HeightShape),
            batch_size=self.batch_size,
            class_mode=self.class_mode
        )
        return train_test_gen
    def transfer_learning(self,activation,loss,optimizer,metrics):
        self.image_in=Input(shape=(self.WidthShape,self.HeightShape,self.channel))
        self.model_t=VGG16(input_tensor=self.image_in,include_top=True,weights='imagenet')
        self.last_layer_model=self.model_t.get_layer('fc2').output
        self.out=Dense(self.class_numbers,activation=activation,name='output')(self.last_layer_model)
        self.my_model=Model(self.image_in,self.out)
        for layer in self.my_model.layers[:-1]:
            layer.trainable=False
        self.my_model.compile(loss=loss,optimizer=optimizer,metrics=metrics)
    def train_model(self,train_gen,test_gen):
        self.hist_model=self.my_model.fit(train_gen,
        epochs=self.epochs,
        validation_data=test_gen,
        steps_per_epoch=train_gen.n//self.batch_size,
        validation_steps=test_gen.n//self.batch_size,
        )
    def save_model(self,path):
        self.my_model.save(path)
    def metrics_report(self,train_gen,path=''):
        self.class_names=list(train_gen.class_indices.keys())
        print(self.class_names)
        test_datagen=ImageDataGenerator()
        test_gen=test_datagen.flow_from_directory(
            self.data_test,
            target_size=(self.WidthShape,self.HeightShape),
            batch_size=self.batch_size,
            class_mode=self.class_mode,
            shuffle=False
        )
        if path!='':
            self.model_load=load_model(path,compile=False)
            predictions=self.model_load.predict_generator(generator=test_gen)
        else:
            predictions=self.my_model.predict_generator(generator=test_gen)
        y_pred=np.argmax(predictions,axis=1)
        y_real=test_gen.classes
        con_matrix=confusion_matrix(y_real,y_pred)
        plot=plot_confusion_matrix(conf_mat=con_matrix,figsize=(9,9),show_normed=False,class_names=self.class_names)
        return metrics.classification_report(y_real,y_pred, digits = 3),plot

roots = [
    ('/content/drive/MyDrive/files/datos_banana_NUEVO/train','/content/drive/MyDrive/files/datos_banana_NUEVO/test','/content/drive/MyDrive/files/Models/bana2_RMS.h5'),
      ('/content/drive/MyDrive/files/datos_trigo/train','/content/drive/MyDrive/files/datos_trigo/test','/content/drive/MyDrive/files/Models/trigo2_RMS.h5')

]

def set_model(path_train,path_test,model_n):
  data_train=path_train
  data_test= path_test
  class_numbers=len(os.listdir(path_train))
  epochs=30
  batch_size=32
  Model_1=model(data_train,data_test,class_numbers,epochs,batch_size)
  train_dgen=Model_1.set_image_datagen(20,0.2,0.1,0.1,preprocess_input)
  test_dgen=Model_1.set_image_datagen(20,0.2,0.1,0.1,preprocess_input)
  train_gen=Model_1.set_image_generator(train_dgen,'categorical',data_train)
  test_gen=Model_1.set_image_generator(test_dgen,'categorical',data_test)
  return Model_1,train_gen,test_gen

for (path_train,path_test,model_n) in roots:
  Model_1,train_gen,test_gen=set_model(path_train,path_test,model_n)
  with tf.device('/gpu:0'):
    Model_1.transfer_learning('softmax','categorical_crossentropy','RMSprop',['accuracy'])
    Model_1.train_model(train_gen,test_gen)
  Model_1.save_model(model_n)

#Las metricas
def load_metrics():
    path_train,path_test,y=roots[0]
    Model_1,train_gen,test_gen=set_model(path_train,path_test)
    cl_r,plot=Model_1.metrics_report(train_gen,'/content/drive/MyDrive/files/Models/papa_RMS.h5')
    print(cl_r)

Model_1.save_model('/content/drive/MyDrive/files/Models/tomate_RMS.h5')

!pip install openai

import os
import openai

openai.api_key = os.getenv("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")

response = openai.Completion.create(
  model="code-davinci-002",
  prompt="\"\"\"\nUtil exposes the following:\nutil.openai() -> authenticates & returns the openai module, which has the following functions:\nopenai.Completion.create(\n    prompt=\"<my prompt>\", # The prompt to start completing from\n    max_tokens=123, # The max number of tokens to generate\n    temperature=1.0 # A measure of randomness\n    echo=True, # Whether to return the prompt in addition to the generated completion\n)\n\"\"\"\nimport util\n\"\"\"\nCreate an OpenAI completion starting from the prompt \"Once upon an AI\", no more than 5 tokens. Does not include the prompt.\n\"\"\"\n",
  temperature=0,
  max_tokens=64,
  top_p=1.0,
  frequency_penalty=0.0,
  presence_penalty=0.0,
  stop=["\"\"\""]
)

import os
import openai
import random
openai.api_key = "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"
engines = openai.Engine.list()
#print(engines)
# print the first engine's id
#print(engines.data[0].id)

# create a completion
preguntas_fr=['Que es el tomate','Como se cultiva el tomate','Como se siembra el tomate']
random.shuffle(preguntas_fr)

completion = openai.Completion.create(prompt=preguntas_fr[0],model="text-davinci-003",
  max_tokens=100)

# print the completion
print(completion['choices'][0]['text'])

import random
import numpy as np
preguntas_fr=np.array(['Que es el tomate','Como se culitva','Etc','Etc2'])
random.shuffle(preguntas_fr)
preguntas_fr[0]

frutas={'tomate':[['Por defecto'],['Que es el tomate','Como se cultiva','Etc','Etc2']],'Manzana':[]}

random.shuffle(frutas['tomate'][1])
frutas['tomate'][1]